{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"48vAXjSNQSI3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import os\n","import sys\n","import datetime\n","\n","from sklearn.preprocessing import StandardScaler, FunctionTransformer\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import matplotlib.dates as mdates\n","plt.style.use('seaborn-whitegrid')\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYX1T_zSVIvI"},"outputs":[],"source":["## Mount Google drive folder if running in Colab\n","if('google.colab' in sys.modules):\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/Research/MSIS_RandD/IndustrialTimeSeries/ForStudents'\n","    DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/Research/MSIS_RandD/IndustrialTimeSeries/Data/'\n","else:\n","    DATA_DIR = 'Data/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzPfv_CVyDpq"},"outputs":[],"source":["## Read data\n","FILE = DATA_DIR + 'data.csv'\n","df = pd.read_csv(FILE, sep = \",\", header = 0)\n","df['time'] = pd.to_datetime(df['time'], format='%m-%d-%Y %H.%M')\n","df = df.set_index('time')\n","df.loc[:, df.columns != 'time'] = df.loc[:, df.columns != 'time'].apply(pd.to_numeric, errors = 'coerce')\n","s = df.select_dtypes(include = 'object').columns\n","df[s] = df[s].astype('float')\n","df.dtypes"]},{"cell_type":"code","source":["## Plot timeseries data\n","colors = cm.rainbow(np.linspace(0, 1, 6))\n","fig, ax = plt.subplots(2, 3, figsize = (14, 6), tight_layout = True)\n","for i in range(2):\n","  for j in range(3):\n","    col = df.columns[i+2*j]\n","    ax[i,j].plot(df.index[df[col].notna()], df[col][df[col].notna()], color = colors[i+2*j])\n","    ax[i, j].set_xlabel('Timestamp', fontsize = 8)\n","    ax[i, j].set_ylabel('Values', fontsize = 8)\n","    ax[i, j].set_title(col, fontsize = 12)\n","    ax[i, j].xaxis.set_major_locator(mdates.MonthLocator(bymonth = range(1, 12, 3)))\n","    ax[i, j].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n","    ax[i, j].tick_params(axis = 'x', rotation = 90);"],"metadata":{"id":"GWBo2HAGdAhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vi5aIXFAgAZ9"},"outputs":[],"source":["## Plot percentage of missing values (NaNs) for each feature\n","fig = plt.figure(figsize=(4, 4))\n","fig.tight_layout()\n","percent_missing = (df.isna().sum() / df.shape[0]) * 100\n","percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n","fig.suptitle('Percentage Missing Values Across All Features', fontsize = 12)\n","plt.xlabel('Feature', fontsize = 10)\n","plt.ylabel('% Missing Values', fontsize = 10);"]},{"cell_type":"code","source":["## Get timestamps of missing values for each column\n","## and plot them\n","fig, ax = plt.subplots(1, 1, figsize = (8, 4), tight_layout = True)\n","for j, col in enumerate(df.columns):\n","  # Get missing timestamps for this column\n","  missing_value_timestamps = df.index[df[col].isna()]\n","  # Plot missing timestamps for this column\n","  ax.scatter(missing_value_timestamps, [0+j] * len(missing_value_timestamps),\n","              color = colors[j],\n","              s = 5,\n","              label = col)\n","\n","ax.set_title('Missing timestamps', fontsize = 12)\n","ax.set_xlabel('Timestamp', fontsize = 10)\n","ax.legend(loc = 'center left', bbox_to_anchor = (1, 0.5))\n","ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth = range(1, 12, 3)))\n","ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n","ax.tick_params(axis = 'x', rotation = 90);"],"metadata":{"id":"FoysEh6Ag5c9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KX12wcB4QSI-"},"outputs":[],"source":["## Linear interpolation for missing values\n","#df['Cyclone_Inlet_Gas_Temp'] = df['Cyclone_Inlet_Gas_Temp'].interpolate(method = 'linear')\n","df.loc[:, (df.columns != 'time')] = df.loc[:, df.columns != 'time'].interpolate(method = 'linear')\n","(df.isna().sum() / df.shape[0]) * 100"]},{"cell_type":"code","source":["## Downsample to daily frequency and plot timeseries data\n","df_daily = df.resample('D').mean()\n","fig, ax = plt.subplots(2, 3, figsize = (14, 6), tight_layout = True)\n","for i in range(2):\n","  for j in range(3):\n","    col = df_daily.columns[i+2*j]\n","    ax[i,j].plot(df_daily.index[df_daily[col].notna()], df_daily[col][df[col].notna()], color = colors[i+2*j])\n","    ax[i, j].set_xlabel('Timestamp', fontsize = 8)\n","    ax[i, j].set_ylabel('Values', fontsize = 8)\n","    ax[i, j].set_title(col, fontsize = 12)\n","    ax[i, j].xaxis.set_major_locator(mdates.MonthLocator(bymonth = range(1, 12, 3)))\n","    ax[i, j].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n","    ax[i, j].tick_params(axis = 'x', rotation = 90);"],"metadata":{"id":"pDzk5jgGrAEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cz2qTKOtBO0I"},"outputs":[],"source":["## Data preparation for anomaly detection using numpy\n","# Note that 5min is the sampling period in the dataset which\n","# we specify and convert to seconds\n","sampling_period = int(pd.Timedelta('5min').total_seconds())\n","# We are interested in 30min data for each sample which\n","# we specify and convert to seconds\n","time_period = int(pd.Timedelta('30min').total_seconds())\n","# The following is a dictionary that we will use for transforming the columns\n","# 'identity' corresponds to no transformation, 'standard' means standardizing\n","scaler = {'identity': FunctionTransformer(lambda x: x), 'standard': StandardScaler()}\n","df_transformed = pd.DataFrame(scaler['standard'].fit_transform(df))\n","df_transformed.columns = df.columns.copy()\n","df_transformed.index = df.index.copy()\n","ncols_reshape = int(pd.Timedelta(str(time_period/sampling_period)+'S').total_seconds())\n","nrows_reshape = df_transformed.shape[0]//ncols_reshape\n","df_samples = pd.DataFrame(np.concatenate([np.array(df_transformed[feature])[0:nrows_reshape*ncols_reshape].reshape(nrows_reshape, ncols_reshape) for feature in df_transformed.columns.values], axis = 1))\n","df_samples.index = pd.date_range(df_transformed.index.min(),\n","                                 df_transformed.index.max() + pd.DateOffset(days = 1),\n","                                 normalize = True,\n","                                 freq = str(time_period)+'S')[0:df_samples.shape[0]]\n","df_samples.head()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"vscode":{"interpreter":{"hash":"854f9ff9f945bab8ba5d04e939504df285fc62eb45b7a687b185fca2375459b7"}}},"nbformat":4,"nbformat_minor":0}